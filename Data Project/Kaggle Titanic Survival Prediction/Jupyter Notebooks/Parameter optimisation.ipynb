{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "b635e788",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.model_selection import RandomizedSearchCV\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn import tree\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.svm import SVC\n",
    "from xgboost import XGBClassifier\n",
    "from sklearn.ensemble import VotingClassifier\n",
    "import pandas as pd\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "9ffc0f91",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load data\n",
    "\n",
    "X_train = pd.read_pickle(\"../Data/X_train.pkl\")\n",
    "X_test = pd.read_pickle(\"../Data/X_test.pkl\")\n",
    "y_train = pd.read_pickle(\"../Data/y_train.pkl\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "f31d0ecb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Prints the parameters leading to the highest score of a model\n",
    "\n",
    "def clf_performance(clf, model_name):\n",
    "    print(model_name)\n",
    "    print('Best Score: ' + str(clf.best_score_))\n",
    "    print('Best Parameters: ' + str(clf.best_params_))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "6b4aecb2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 40 candidates, totalling 200 fits\n",
      "Logistic Regression\n",
      "Best Score: 0.7941979305529104\n",
      "Best Parameters: {'C': 0.03359818286283781, 'max_iter': 2000, 'penalty': 'l2', 'solver': 'liblinear'}\n"
     ]
    }
   ],
   "source": [
    "# Find the particular parameters that lead to the highest score\n",
    "\n",
    "lr = LogisticRegression()\n",
    "param_grid = {\n",
    "    'max_iter': [2000],\n",
    "    'penalty': ['l1', 'l2'],\n",
    "    'C': np.logspace(-4,4,20),\n",
    "    'solver': ['liblinear']\n",
    "    \n",
    "}\n",
    "\n",
    "clf_lr = GridSearchCV(lr, param_grid = param_grid, cv = 5, verbose = True, n_jobs = -1)\n",
    "clf_lr_best = clf_lr.fit(X_train, y_train)\n",
    "clf_performance(clf_lr_best, 'Logistic Regression')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "57b82fc5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 48 candidates, totalling 240 fits\n",
      "KNN\n",
      "Best Score: 0.8031739986034406\n",
      "Best Parameters: {'algorithm': 'auto', 'n_neighbors': 7, 'p': 1, 'weights': 'uniform'}\n"
     ]
    }
   ],
   "source": [
    "# Find the particular parameters that lead to the highest score\n",
    "\n",
    "knn = KNeighborsClassifier()\n",
    "param_grid = {\n",
    "    'n_neighbors': [3,5,7,9],\n",
    "    'weights' : ['uniform', 'distance'],\n",
    "    'algorithm': ['auto', 'ball_tree', 'kd_tree'],\n",
    "    'p': [1,2]\n",
    "    \n",
    "}\n",
    "\n",
    "clf_knn = GridSearchCV(knn, param_grid = param_grid, cv = 5, verbose = True, n_jobs = -1)\n",
    "best_clf_knn = clf_knn.fit(X_train, y_train)\n",
    "clf_performance(best_clf_knn, 'KNN')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "248f6c84",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Find the particular parameters that lead to the highest score\n",
    "\n",
    "svc = SVC(probability = True)\n",
    "param_grid = tuned_parameters = [{'kernel': ['rbf'], 'gamma': [.1, .5, 1, 2, 5, 10], 'C': [.1,1,10,100,1000]},\n",
    "                                 {'kernel': ['linear'], 'C': [.1,1,10,100,1000]},\n",
    "                                {'kernel': ['poly'], 'degree':[2,3,4,5], 'C': [.1,1,10,100,1000]}\n",
    "                                ]\n",
    "\n",
    "clf_svc = GridSearchCV(svc, param_grid = param_grid, cv = 5, verbose = 5, n_jobs = -1)\n",
    "best_clf_svc = clf_svc.fit(X_train, y_train)\n",
    "clf_performance(best_clf_svc, 'SVC')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8ed1d8f7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Find the particular parameters that lead to the highest score\n",
    "\n",
    "rf = RandomForestClassifier(random_state = 1)\n",
    "param_grid =  {'n_estimators': [100,500,1000], \n",
    "                                  'bootstrap': [True,False],\n",
    "                                  'max_depth': [3,5,10,20,50,75,100,None],\n",
    "                                  'max_features': ['auto','sqrt'],\n",
    "                                  'min_samples_leaf': [1,2,4,10],\n",
    "                                  'min_samples_split': [2,5,10]}\n",
    "                                  \n",
    "clf_rf_rnd = RandomizedSearchCV(rf, param_distributions = param_grid, n_iter = 100, cv = 5, verbose = True, n_jobs = -1)\n",
    "best_clf_rf_rnd = clf_rf_rnd.fit(X_train,y_train)\n",
    "clf_performance(best_clf_rf_rnd,'Random Forest')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8be984cb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Find the particular parameters that lead to the highest score\n",
    "\n",
    "best_rf = best_clf_rf.best_estimator_.fit(X_train, y_train)\n",
    "feat_importances = pd.Series(best_rf.feature_importances_, index = X_train.columns)\n",
    "feat_importances.nlargest(20).plot(kind = 'barh')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e87a6bd2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Find the particular parameters that lead to the highest score\n",
    "\n",
    "xgb = XGBClassifier(random_state = 1)\n",
    "\n",
    "param_grid = {\n",
    "    'n_estimators': [20, 50, 100, 250, 500,1000],\n",
    "    'colsample_bytree': [0.2, 0.5, 0.7, 0.8, 1],\n",
    "    'max_depth': [2, 5, 10, 15, 20, 25, None],\n",
    "    'reg_alpha': [0, 0.5, 1],\n",
    "    'reg_lambda': [1, 1.5, 2],\n",
    "    'subsample': [0.5,0.6,0.7, 0.8, 0.9],\n",
    "    'learning_rate':[.01,0.1,0.2,0.3,0.5, 0.7, 0.9],\n",
    "    'gamma':[0,.01,.1,1,10,100],\n",
    "    'min_child_weight':[0,.01,0.1,1,10,100],\n",
    "    'sampling_method': ['uniform', 'gradient_based']\n",
    "}\n",
    "\n",
    "#clf_xgb = GridSearchCV(xgb, param_grid = param_grid, cv = 5, verbose = True, n_jobs = -1)\n",
    "#best_clf_xgb = clf_xgb.fit(X_train_scaled,y_train)\n",
    "#clf_performance(best_clf_xgb,'XGB')\n",
    "clf_xgb_rnd = RandomizedSearchCV(xgb, param_distributions = param_grid, n_iter = 1000, cv = 5, verbose = True, n_jobs = -1)\n",
    "best_clf_xgb_rnd = clf_xgb_rnd.fit(X_train,y_train)\n",
    "clf_performance(best_clf_xgb_rnd,'XGB')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ca22ba7a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Find the particular parameters that lead to the highest score\n",
    "\n",
    "xgb = XGBClassifier(random_state = 1)\n",
    "\n",
    "param_grid = {\n",
    "    'n_estimators': [450,500,550],\n",
    "    'colsample_bytree': [0.75,0.8,0.85],\n",
    "    'max_depth': [None],\n",
    "    'reg_alpha': [1],\n",
    "    'reg_lambda': [2, 5, 10],\n",
    "    'subsample': [0.55, 0.6, .65],\n",
    "    'learning_rate':[0.5],\n",
    "    'gamma':[.5,1,2],\n",
    "    'min_child_weight':[0.01],\n",
    "    'sampling_method': ['uniform']\n",
    "}\n",
    "\n",
    "clf_xgb = GridSearchCV(xgb, param_grid = param_grid, cv = 5, verbose = True, n_jobs = -1)\n",
    "best_clf_xgb = clf_xgb.fit(X_train,y_train)\n",
    "clf_performance(best_clf_xgb,'XGB')\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1662b544",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Make a prediction based on the best xgb model\n",
    "\n",
    "y_hat_xgb = best_clf_xgb.best_estimator_.predict(X_test).astype(int)\n",
    "xgb_submission = {'PassengerId': X_test.index, 'Survived': y_hat_xgb}\n",
    "submission_xgb = pd.DataFrame(data = xgb_submission)\n",
    "submission_xgb.to_csv('../Submissions/sgb_submission.csv', index = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "22b7816c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Use a voting classifier to find the best scores using all the different models\n",
    "\n",
    "best_lr = clf_lr_best.best_estimator_\n",
    "best_knn = best_clf_knn.best_estimator_\n",
    "best_svc = best_clf_svc.best_estimator_\n",
    "best_rf = best_clf_rf.best_estimator_\n",
    "best_xgb = best_clf_xgb.best_estimator_\n",
    "\n",
    "voting_clf_hard = VotingClassifier(estimators = [('knn', best_knn), ('rf', best_rf), ('svc', best_svc)], voting = 'hard')\n",
    "voting_clf_soft = VotingClassifier(estimators = [('knn', best_knn), ('svc', best_svc), ('rf', best_rf)], voting = 'soft')\n",
    "\n",
    "voting_clf_all = VotingClassifier(estimators = [('knn', best_knn), ('svc', best_svc), ('rf', best_rf), ('xgb', best_xgb), ('lr', best_lr)\n",
    "    ], voting = 'soft')\n",
    "\n",
    "print('voting_clf_hard: ', cross_val_score(voting_clf_hard, X_train, y_train, cv = 5))\n",
    "print('voting_clf_hard: ', cross_val_score(voting_clf_hard, X_train, y_train, cv = 5).mean())\n",
    "\n",
    "print('voting_clf_soft: ', cross_val_score(voting_clf_soft, X_train, y_train, cv = 5))\n",
    "print('voting_clf_soft: ', cross_val_score(voting_clf_soft, X_train, y_train, cv = 5).mean())\n",
    "\n",
    "print('voting_clf_all: ', cross_val_score(voting_clf_all, X_train, y_train, cv = 5))\n",
    "print('voting_clf_all: ', cross_val_score(voting_clf_all, X_train, y_train, cv = 5).mean())\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "40edfce7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Use a voting classifier to find the best scores using all the different models with different weights for models\n",
    "\n",
    "params = {'weights': [[1,1,1], [1,2,1], [1,1,2], [2,1,1], [2,2,1], [2,1,2], [1,2,2]]}\n",
    "\n",
    "vote_weight = GridSearchCV(voting_clf_soft, param_grid = params, cv=5, verbose = True, n_jobs = -1)\n",
    "best_clf_weight = vote_weight.fit(X_train, y_train)\n",
    "clf_performance(best_clf_weight, 'VC Weights')\n",
    "voting_clf_sub = best_clf_weight.best_estimator_.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1fb84ef3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Find the scores for each voting classifier\n",
    "\n",
    "voting_clf_hard.fit(X_train, y_train)\n",
    "voting_clf_soft.fit(X_train, y_train)\n",
    "voting_clf_all.fit(X_train, y_train)\n",
    "\n",
    "best_rf.fit(X_train, y_train)\n",
    "y_hat_vc_hard = voting_clf_hard.predict(X_test).astype(int)\n",
    "y_hat_rf = best_rf.predict(X_test).astype(int)\n",
    "y_hat_vc_soft = voting_clf_soft.predict(X_test).astype(int)\n",
    "y_hat_vc_all = voting_clf_all.predict(X_test).astype(int)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7047b96d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Make submissions based on the different voting classifiers\n",
    "\n",
    "final_data = {'PassengerId': X_test.index, 'Survived': y_hat_rf}\n",
    "submission = pd.DataFrame(data=final_data)\n",
    "\n",
    "final_data_2 = {'PassengerId': X_test.index, 'Survived': y_hat_vc_hard}\n",
    "submission_2 = pd.DataFrame(data=final_data_2)\n",
    "\n",
    "final_data_3 = {'PassengerId': X_test.index, 'Survived': y_hat_vc_soft}\n",
    "submission_3 = pd.DataFrame(data=final_data_3)\n",
    "\n",
    "final_data_4 = {'PassengerId': X_test.index, 'Survived': y_hat_vc_all}\n",
    "submission_4 = pd.DataFrame(data=final_data_4)\n",
    "\n",
    "final_data_comp = {'PassengerId': X_test.index, 'Survived_vc_hard': y_hat_vc_hard, 'Survived_rf': y_hat_rf, 'Survived_vc_soft' : y_hat_vc_soft, 'Survived_vc_all' : y_hat_vc_all,  }\n",
    "comparison = pd.DataFrame(data=final_data_comp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "45b21bcb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compare the voting classifiers\n",
    "\n",
    "comparison['difference_rf_vc_hard'] = comparison.apply(lambda x: 1 if x.Survived_vc_hard != x.Survived_rf else 0, axis =1)\n",
    "comparison['difference_soft_hard'] = comparison.apply(lambda x: 1 if x.Survived_vc_hard != x.Survived_vc_soft else 0, axis =1)\n",
    "comparison['difference_hard_all'] = comparison.apply(lambda x: 1 if x.Survived_vc_all != x.Survived_vc_hard else 0, axis =1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "afc60200",
   "metadata": {},
   "outputs": [],
   "source": [
    "comparison.difference_hard_all.value_counts()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
